# Deployment Guide - Ready to Deploy

## âœ… What's Fixed and Ready

Your Terraform configuration is now **fully validated and ready to deploy**:
- Helm provider syntax: âœ… Fixed
- Terraform state: âœ… Clean
- Configuration validation: âœ… Passed
- AWS Load Balancer Controller: âœ… Auto-deploy configured

## ğŸš€ Quick Start - Deploy EKS Cluster

### Step 1: Deploy Bootstrap Infrastructure (One-Time)
Only needed if you haven't already created the S3 state bucket:

```bash
cd terraform/bootstrap
terraform init
terraform apply
# Note the bucket name output
```

### Step 2: Deploy Dev Environment Cluster

```bash
cd terraform/environments/dev
terraform init
terraform plan    # Review what will be created (~15-20 min to deploy)
terraform apply
```

**Resources Created:**
- EKS Cluster (Kubernetes 1.31)
- 1 t3.micro node (SPOT instance for cost savings)
- VPC with public subnets
- Security groups and IAM roles
- ECR repository (aetush-dev-cluster-ecr)
- **AWS Load Balancer Controller** (auto-installed via Helm)

**Estimated Cost:** ~$5-10/month for dev environment

### Step 3: Configure kubectl

```bash
# Use the output from terraform apply or run:
aws eks update-kubeconfig --region eu-central-1 --name aetush-dev-cluster

# Verify cluster access:
kubectl get nodes
kubectl get pods -n kube-system
```

### Step 4: Verify Load Balancer Controller

```bash
# Check if AWS Load Balancer Controller is running:
kubectl get pods -n kube-system | grep aws-load-balancer-controller
kubectl logs -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller -f
```

## ğŸ“¦ Deploy sre-portal Application

### Step 1: Build and Push Docker Image

```bash
cd app/sre-portal

# Build image
docker build -t sre-portal:v1.0.0 .

# Get login credentials and push to ECR
aws ecr get-login-password --region eu-central-1 | \
  docker login --username AWS --password-stdin 745865830379.dkr.ecr.eu-central-1.amazonaws.com

# Tag image
docker tag sre-portal:v1.0.0 \
  745865830379.dkr.ecr.eu-central-1.amazonaws.com/aetush-dev-cluster-ecr:v1.0.0

# Push to ECR
docker push 745865830379.dkr.ecr.eu-central-1.amazonaws.com/aetush-dev-cluster-ecr:v1.0.0
```

### Step 2: Deploy via Helm

```bash
# From project root
helm install sre-portal ./k8s/sre-portal \
  -f ./k8s/sre-portal/values-dev.yaml \
  --set image.tag=v1.0.0

# Verify deployment
kubectl get pods
kubectl logs -l app=sre-portal -f
```

### Step 3: Test Application

```bash
# Port forward to access locally
kubectl port-forward svc/sre-portal 3000:3000

# In browser: http://localhost:3000
# Check health: http://localhost:3000/health
# View metrics: http://localhost:3000/metrics
```

## ğŸ”§ Troubleshooting

### Helm Provider Hangs on Waiting for Node
If `terraform apply` hangs waiting for the Helm release to install:
- This typically means the node hasn't fully initialized yet
- You can interrupt (Ctrl+C) and re-run `terraform apply`
- The module will skip already-created resources and retry the Helm release

**Alternative:** Deploy Helm release manually after cluster is ready:
```bash
helm repo add eks https://aws.github.io/eks-charts
helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
  -n kube-system \
  --set clusterName=aetush-dev-cluster \
  --set serviceAccount.annotations."eks\.amazonaws\.com/role-arn"=<LB_CONTROLLER_ROLE_ARN>
```

### Ingress Not Working
1. Verify Load Balancer Controller is running: `kubectl get pods -n kube-system`
2. Check ingress status: `kubectl get ingress`
3. View ingress details: `kubectl describe ingress sre-portal`
4. Check AWS console â†’ EC2 â†’ Load Balancers for the ALB

### Out of Free Tier
If you get AWS service quota or billing warnings:
1. Set `desired_size = 0` in `terraform/environments/dev/terraform.tfvars`
2. Run `terraform apply` to spin down nodes
3. Cluster stays provisioned, just no running nodes
4. Set back to 1 when needed

## ğŸ“‹ Architecture Summary

```
AWS Region: eu-central-1
â”œâ”€â”€ VPC (10.0.0.0/16)
â”‚   â”œâ”€â”€ Public Subnet 1 (10.0.0.0/24)
â”‚   â”œâ”€â”€ Public Subnet 2 (10.0.1.0/24)
â”‚   â””â”€â”€ Internet Gateway
â”œâ”€â”€ EKS Cluster (1.31)
â”‚   â”œâ”€â”€ 1 t3.micro Node (SPOT)
â”‚   â”œâ”€â”€ AWS Load Balancer Controller (Helm release)
â”‚   â””â”€â”€ 1 sre-portal Pod
â”œâ”€â”€ ECR Repository (aetush-dev-cluster-ecr)
â””â”€â”€ IAM Roles (Cluster, Nodes, LB Controller)
```

## âœ¨ What's Automated

âœ… Cluster creation and configuration  
âœ… VPC and networking setup  
âœ… IAM roles and policies  
âœ… ECR repository creation  
âœ… AWS Load Balancer Controller installation  
âœ… Kubernetes configuration  
âœ… Multi-environment ready (just copy environments/dev â†’ staging/prod)  

## ğŸ“ Next: GitHub Actions CI/CD

Once everything is working, create `.github/workflows/deploy.yml` to automate:
- Building Docker images on git push
- Pushing to ECR
- Deploying via Helm to EKS
- Running tests and validations
